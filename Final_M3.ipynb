{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_M3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFycu5aIi93O"
      },
      "source": [
        "#MILESTONE 3#\n",
        "Ali Wehbi - Dina Younes - Reeda Al Saintbai - Shaza Fakih - Youssef Jaafar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRKGwPQrdEIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7926ffa3-6f8d-4f7f-b6cb-086bdf8802f0"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB1dN7Hzfy0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670c6eb6-8e62-41d9-c03d-9ef0e25d79f7"
      },
      "source": [
        "import pandas as pd\n",
        "#######################################################################################################################################################\n",
        "######### Make sure the path is correct before running ################################################################################################\n",
        "df = pd.read_csv(\"/content/drive/My Drive/iseardataset.csv\")       #importing the ISEAR dataset into a dataframe\n",
        "#df = pd.read_csv(\"/content/iseardataset.csv\")   \n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     label                                               text Unnamed: 2\n",
            "0      joy  On days when I feel close to my partner and ot...        NaN\n",
            "1     fear  Every time I imagine that someone I love or I ...        NaN\n",
            "2    anger  When I had been obviously unjustly treated and...        NaN\n",
            "3  sadness  When I think about the short time that we live...        NaN\n",
            "4  disgust  At a gathering I found myself involuntarily si...        NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGZGidWhgKDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809d3d9f-0a9a-43e2-900d-aaf51c6bb73b"
      },
      "source": [
        "#Removing last column\n",
        "df = df[['label','text']] \n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     label                                               text\n",
            "0      joy  On days when I feel close to my partner and ot...\n",
            "1     fear  Every time I imagine that someone I love or I ...\n",
            "2    anger  When I had been obviously unjustly treated and...\n",
            "3  sadness  When I think about the short time that we live...\n",
            "4  disgust  At a gathering I found myself involuntarily si...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNL2hvM7otzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ca8dbb-a7f8-4cba-fb6b-f1744523e46d"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7516 entries, 0 to 7515\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   label   7516 non-null   object\n",
            " 1   text    7516 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 117.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3clr9zjlIKy"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Preprocessing of data#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qphYCgxB2xAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8eafca-50c7-4671-f683-6120dfb88449"
      },
      "source": [
        "#importing necessary libraries for preprocessing\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')    # stop words do not contribute in giving a meaning to a sentence, hence they can be ignored\n",
        "\n",
        "def DataPreprocess(input_text):\n",
        "  \"\"\"\n",
        "  Function that takes text input as string, converts text into lowercase, removes non alphabetic words, tokenizes the text, \n",
        "  reduces each word to its root\n",
        "  \"\"\"\n",
        "  input_text = input_text.lower()                   #converting to lower case\n",
        "  input_text = re.sub(r'[^a-z]', ' ', input_text)   #keeping alphabetic words only\n",
        "  text_tokens = word_tokenize(input_text)           #creating tokens of the text\n",
        "\n",
        "  #print(\"Tokens:\", text_tokens)\n",
        "  #print('\\n')\n",
        "\n",
        "  porter_stemmer = PorterStemmer()                                     #initializing a stemmer\n",
        "  porter_stemmed = [porter_stemmer.stem(word) for word in text_tokens] #stemming words, i.e. reducing a word to its root. \n",
        "  input_text = ' '.join(porter_stemmed)                                #after preprocessing, create full text back\n",
        "  #print(\"After preprocessing, before stopwords:\")\n",
        "  #print(input_text)\n",
        "  #print('\\n')\n",
        "  # remove stopwords\n",
        "  input_text = ' '.join([word for word in input_text.split() if word not in stop_words])\n",
        "  #print(\"After stopwords:\")\n",
        "  #print('\\n')\n",
        "  return input_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7foahL049y1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f01568-6d6c-4a2c-c6df-aff8ca224adf"
      },
      "source": [
        "df['text'] = df['text'].apply(DataPreprocess)    #Preprocessing the input data\n",
        "df.head() \n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     label                                               text\n",
            "0      joy  day feel close partner friend feel peac also e...\n",
            "1     fear  everi time imagin someon love could contact se...\n",
            "2    anger          obvious unjustli treat possibl elucid thi\n",
            "3  sadness  think short time live relat period life think ...\n",
            "4  disgust  gather found involuntarili sit next two peopl ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bcSjR8U-0J5"
      },
      "source": [
        "#Feature Engineering#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kC4HJl7pk2j"
      },
      "source": [
        "#importing necessary libraries to create & train the model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = df.text.to_numpy()        #converting the pandas series to a numpy array\n",
        "#X = X.reshape(-1,1)\n",
        "y = df.label.values           #returning a numpy representation of the dataframe data.label\n",
        "#y = y.reshape(-1,1)\n",
        "#print(X)\n",
        "#print(y)\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "\n",
        "#Splitting the data into a training set and a testing set with 80-20% proportions and a random state = 52\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=52)\n",
        "T_vectorizer = TfidfVectorizer(min_df=2, max_df=0.9)    #instantiating the vectorizer object\n",
        "vect_train = T_vectorizer.fit_transform(X_train)        #transforming train and test data into a matrix of TF-IDF features\n",
        "vect_test = T_vectorizer.transform(X_test)              #in order to transform text into a significant representation of numbers\n",
        "#print(vect_train)\n",
        "#print(vect_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzD8hUg1Wsc"
      },
      "source": [
        "#Model Building#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu2xq-BH1Vbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcb2d35-b411-4bb8-a93e-6867d547f2c9"
      },
      "source": [
        "\n",
        "model = svm.SVC(kernel='linear')                             #initializing an SVM model\n",
        "model.fit(vect_train, y_train)                               #training the model on the training set\n",
        "emotion_predicted = model.predict(vect_test)                 #measuring the quality of the model's prediction on the test set\n",
        "print(classification_report(y_test, emotion_predicted))      #displaying the precision, recall, F1, and support scores for the model.\n",
        "                                              "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.39      0.54      0.45       193\n",
            "     disgust       0.59      0.52      0.55       215\n",
            "        fear       0.66      0.72      0.69       208\n",
            "       guilt       0.47      0.44      0.46       214\n",
            "         joy       0.70      0.69      0.69       205\n",
            "     sadness       0.68      0.62      0.65       228\n",
            "       shame       0.53      0.46      0.49       241\n",
            "\n",
            "    accuracy                           0.57      1504\n",
            "   macro avg       0.57      0.57      0.57      1504\n",
            "weighted avg       0.58      0.57      0.57      1504\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgRVYIyb36Cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e665b6f-da79-4c3e-e747-750442304c12"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "c_matrix = confusion_matrix(emotion_predicted, y_test)          #using a confusion matrix to evaluate the model\n",
        "print(c_matrix)                                                 #this is useful in model management and monitoring and used to evaluate the perfomance of our classification model  \n",
        "print(\"Accuracy: \",accuracy_score(y_test, emotion_predicted))   #printing the accuracy of the model after predicting on the test set\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[105  38  15  45   7  18  43]\n",
            " [ 18 111   7  10   9  10  23]\n",
            " [  9  12 150  17  11  17  13]\n",
            " [ 24  16  11  94  12  15  27]\n",
            " [  7   7   8   5 141  19  15]\n",
            " [ 12   9   7  15  14 141   9]\n",
            " [ 18  22  10  28  11   8 111]]\n",
            "Accuracy:  0.567154255319149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS3PmraL7_4g"
      },
      "source": [
        "def predict(model, T_vectorizer, text):\n",
        "  \"\"\"\n",
        "  function that takes as input a model (in our case svm), a vectorizer (tfid vectorizer in our case), and input text as string\n",
        "  returns the detected emotion in the text\n",
        "  \"\"\"\n",
        "  text = DataPreprocess(text)                      #preprocessing the input text: converting to lower case, removing non-alphabetic words, tokenizing the text, and stemming words\n",
        "  text_vectorized = T_vectorizer.transform([text]) #using the tfidf vectorizer on the input text\n",
        "  return model.predict(text_vectorized)[0]         #running the model on the vectorizer\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMaDmyJMJ7-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baa0595-666a-411d-c05c-f6d0170866ab"
      },
      "source": [
        "text1 = \"Today i went to the mall with my friends to celebrate my friend's birthday, it was great!\"\n",
        "print(\"Emotion predicted: \",predict(model,T_vectorizer,text1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion predicted:  joy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCUa3CUF2pI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b59c29-fe4b-402f-e6a0-3c8448fcc07d"
      },
      "source": [
        "text2 = \"I feel awful today\"\n",
        "print(\"Emotion predicted: \",predict(model,T_vectorizer,text2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion predicted:  shame\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0E3RZ6H76Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3ed3a2-4fa0-4f96-9a29-9cef82edd6db"
      },
      "source": [
        "text3 = \"I have a presentation tomorrow, im feeling nervous. I want it to go well, but i might fail.\"\n",
        "print(\"Emotion predicted: \",predict(model,T_vectorizer,text3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion predicted:  fear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qecEXxQOKBzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d988d17-abdc-46fc-b6f6-3b31921ea6ce"
      },
      "source": [
        "text4 = \"I'm not feeling good\"\n",
        "print(\"Emotion predicted: \",predict(model,T_vectorizer,text4)) #Problem with the negation words, considering them as stop words, they are being removed."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion predicted:  joy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}